{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy import great_circle\n",
    "from sklearn import *\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/yixin/Desktop/Machine_Learning_Projects/restaurant-visitor-forecasting'\n",
    "np.random.seed(2018)\n",
    "\n",
    "data = {\n",
    "    'air_reserve': pd.read_csv(path + '/input/air_reserve.csv', \\\n",
    "                               parse_dates=['visit_datetime', 'reserve_datetime']),\n",
    "    'hpg_reserve': pd.read_csv(path + '/input/hpg_reserve.csv', \\\n",
    "                               parse_dates=['visit_datetime', 'reserve_datetime']),\n",
    "    'air_visit': pd.read_csv(path + '/input/air_visit_data.csv', parse_dates=['visit_date']), # main training set\n",
    "    'holidays': pd.read_csv(path + '/input/date_info.csv', parse_dates=['calendar_date']).rename(\n",
    "        columns={'calendar_date': 'visit_date'}),\n",
    "    'air_store': pd.read_csv(path + '/input/air_store_info.csv'),\n",
    "    'hpg_store': pd.read_csv(path + '/input/hpg_store_info.csv'),\n",
    "    'id': pd.read_csv(path + '/input/store_id_relation.csv'),\n",
    "    'submission': pd.read_csv(path + '/input/sample_submission.csv'),  # test set\n",
    "}\n",
    "\n",
    "data['hpg_reserve'] = pd.merge(data['hpg_reserve'], data['id'], how='inner', on='hpg_store_id')\n",
    "data['holidays'].drop(['day_of_week'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "###                                      Feature Engineering                                        ###\n",
    "#######################################################################################################\n",
    "# Add day of week, month into training set and test set\n",
    "data['submission']['visit_date'] = data['submission']['id'].apply(lambda x:x[-10:])\n",
    "data['submission']['visit_date'] = pd.to_datetime(data['submission']['visit_date'])\n",
    "data['submission']['air_store_id'] = data['submission']['id'].apply(lambda x:x[:-11])\n",
    "data['submission'].drop(['id'], axis=1, inplace=True)\n",
    "for df in ['air_visit', 'submission']:\n",
    "    data[df]['day_of_week'] = data[df]['visit_date'].dt.dayofweek\n",
    "    data[df]['month'] = data[df]['visit_date'].dt.month\n",
    "    data[df]['year'] = data[df]['visit_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add feature, distance referencere (median latitude and median longitude), into air_store    (possible feature)\n",
    "ref = data['air_store'][['latitude', 'longitude']].median().values\n",
    "data['air_store']['diff_dist'] = data['air_store'].apply(lambda x: \\\n",
    "                                great_circle((x['latitude'],x['longitude']), ref).km, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add feature, location reference (median latitude and median longitude), into air_store    (possible feature)\n",
    "data['air_store']['diff_lat_median'] = np.absolute(\n",
    "    data['air_store']['latitude'].median() - data['air_store']['latitude'])\n",
    "data['air_store']['diff_long_median'] = np.absolute(\n",
    "    data['air_store']['longitude'].median() - data['air_store']['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add feature, location reference (max latitude and max longitude), into air_store    (possible feature)\n",
    "data['air_store']['diff_lat_max'] = data['air_store']['latitude'].max() - data['air_store']['latitude']\n",
    "data['air_store']['diff_long_max'] = data['air_store']['longitude'].max() - data['air_store']['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add feature, latitude + longitude, into air_store    (possible feature)\n",
    "data['air_store']['lat_plus_long'] = data['air_store']['latitude'] + data['air_store']['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add feature, prefecture, into air_store    (possible feature)\n",
    "data['air_store']['prefecture'] = data['air_store']['air_area_name'].apply(lambda x:str(x).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add feature, number of restaurants per area, into air_store    (possible feature)\n",
    "tmp = data['air_store'].groupby('air_area_name', as_index=False)['air_store_id'].count().rename(\n",
    "    columns={'air_store_id': 'rest_per_area'})\n",
    "data['air_store'] = pd.merge(data['air_store'], tmp, how='left', on='air_area_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate min, max, median, and mean of visitors grouped by each store and day of week\n",
    "unique_stores = data['submission']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'day_of_week': [i] * len(unique_stores)}) \\\n",
    "                    for i in range(7)], ignore_index=True)\n",
    "\n",
    "funcs = {\n",
    "    'min': 'visitors_min',\n",
    "    'max': 'visitors_max',\n",
    "    'mean': 'visitors_mean',\n",
    "    'median': 'visitors_median',\n",
    "    'count': 'observation_count'\n",
    "}\n",
    "for func in funcs:\n",
    "    tmp = data['air_visit'].groupby(['air_store_id', 'day_of_week'], as_index=False).agg(\n",
    "    {'visitors': func}).rename(columns={'visitors': funcs[func]})\n",
    "    stores = stores.merge(tmp, how='left', on=['air_store_id', 'day_of_week'])\n",
    "stores = stores.merge(data['air_store'], how='left', on='air_store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge training and test sets with holidays\n",
    "train = pd.merge(data['air_visit'], data['holidays'], how='left', on='visit_date')\n",
    "test = pd.merge(data['submission'], data['holidays'], how='left', on='visit_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge training and test sets with store information\n",
    "train = pd.merge(train, stores, how='inner', on=['air_store_id', 'day_of_week'])\n",
    "test = pd.merge(test, stores, how='inner', on=['air_store_id', 'day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle training data\n",
    "train = utils.shuffle(train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define evaluation metric\n",
    "def RMSE(y_true, y_pred):\n",
    "    return metrics.mean_squared_error(y_true, y_pred) ** 0.5\n",
    "rmse = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "###                                         Pre-training                                            ###\n",
    "#######################################################################################################\n",
    "X_cols = [col for col in train.columns if col not in ['air_store_id', 'visit_date', 'visitors']]\n",
    "y_col = ['visitors']\n",
    "X_train = train[X_cols]; X_test = test[X_cols]\n",
    "y_train = np.log1p(train[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "X_train['year'] = le.fit_transform(X_train['year'])\n",
    "\n",
    "categorical_columns = ['day_of_week', 'month', 'air_genre_name', 'air_area_name', 'prefecture']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample pre-training data, size = X_train, with replacement\n",
    "np.random.seed(2018)\n",
    "idx = np.random.randint(X_train.shape[0], size=X_train.shape[0])\n",
    "X_train_pre = X_train.loc[idx]\n",
    "y_train_pre = y_train.loc[idx]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "X, y = X_train_pre.values, y_train_pre.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change and trial any regression method here...\n",
    "reg = ensemble.RandomForestRegressor(n_jobs=-1, max_features=0.8, n_estimators=200)\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_train, rmsle_val = 0, 0\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train_cv, y_train_cv = X[train_idx], np.ravel(y[train_idx])\n",
    "    X_val_cv, y_val_cv = X[val_idx], np.ravel(y[val_idx])\n",
    "    \n",
    "    ##dtrain = xgb.DMatrix(data=X_train_cv, label=y_train_cv)\n",
    "    ##dval = xgb.DMatrix(data=X_val_cv, label=y_val_cv)\n",
    "    ##model = xgb.train(params=params, dtrain=dtrain, num_boost_round=200)\n",
    "    ##yhat_train = model.predict(dtrain, ntree_limit=200)\n",
    "    ##yhat_val = model.predict(dval, ntree_limit=200)\n",
    "    reg.fit(X_train_cv, y_train_cv)\n",
    "    yhat_train = reg.predict(X_train_cv)\n",
    "    yhat_val = reg.predict(X_val_cv)\n",
    "    print('*************************************')\n",
    "    print('RMSLE on training set:', RMSE(y_train_cv, yhat_train))\n",
    "    print('RMSLE on validation set:', RMSE(y_val_cv, yhat_val))\n",
    "    rmsle_train += RMSE(y_train_cv, yhat_train)\n",
    "    rmsle_val += RMSE(y_val_cv, yhat_val)\n",
    "print('Average RMSLE on training set:', rmsle_train / 5)\n",
    "print('Average RMSLE on validation set:', rmsle_val / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(X_train.columns, reg.feature_importances_), key=lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "###                                         Pre-training                                            ###\n",
    "###                          Train a model for each restaurant seperately                           ###\n",
    "#######################################################################################################\n",
    "cols = [col for col in train.columns if col not in ['air_genre_name', 'air_area_name', 'visit_date'\n",
    "                                                    'latitude', 'longitude', 'diff_lat_median', 'diff_lat_max', \n",
    "                                                    'diff_long_median', 'diff_long_max', 'lat_plus_long', \n",
    "                                                    'diff_dist', 'rest_per_area', 'prefecture']]\n",
    "train = train[cols]\n",
    "\n",
    "# Seperate data according to air_store_id\n",
    "X_train, X_test, y_train = {}, {}, {}\n",
    "le = preprocessing.LabelEncoder()\n",
    "drop_columns = ['air_store_id', 'visitors']\n",
    "categorical_columns = ['month', 'day_of_week']\n",
    "\n",
    "for store_id in train['air_store_id'].unique():\n",
    "    if store_id in X_train:\n",
    "        continue\n",
    "    tmp1 = train[train['air_store_id'] == store_id]\n",
    "    tmp2 = test[test['air_store_id'] == store_id]\n",
    "    y_train[store_id] = np.log1p(tmp1['visitors'])\n",
    "    \n",
    "    tmp = pd.concat([tmp1, tmp2], ignore_index=True)\n",
    "    tmp = pd.get_dummies(tmp, columns=categorical_columns)\n",
    "    tmp['year'] = le.fit_transform(tmp['year'])\n",
    "    tmp.drop(drop_columns, axis=1, inplace=True)\n",
    "    \n",
    "    X_train[store_id] = tmp[:tmp1.shape[0]]\n",
    "    X_test[store_id] = tmp[tmp1.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change and trial any regression method here...\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "reg = neighbors.KNeighborsRegressor(n_jobs=-1, weights='distance')\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_train, res_val = 0, 0\n",
    "for store_id in train['air_store_id'].unique():\n",
    "    X, y = X_train[store_id].values, y_train[store_id].values\n",
    "    rmsle_train, rmsle_val = 0, 0\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train_cv, y_train_cv = X[train_idx], np.ravel(y[train_idx])\n",
    "        X_val_cv, y_val_cv = X[val_idx], np.ravel(y[val_idx])\n",
    "            \n",
    "        reg.fit(X_train_cv, y_train_cv)\n",
    "        rmsle_train += RMSE(y_train_cv, reg.predict(X_train_cv))\n",
    "        rmsle_val += RMSE(y_val_cv, reg.predict(X_val_cv))\n",
    "    print('*************************************')\n",
    "    print('RMSLE on {} training set: {}'.format(store_id, rmsle_train / 5))\n",
    "    print('RMSLE on {} validation set: {}'.format(store_id, rmsle_val / 5))\n",
    "    res_train += rmsle_train\n",
    "    res_val += rmsle_val\n",
    "print(res_train / (5 * train['air_store_id'].nunique()))\n",
    "print(res_val / (5 * train['air_store_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "###                                Approximate pre-training outcomes                                ###\n",
    "###                                            Conclusioin                                          ###\n",
    "#######################################################################################################\n",
    "# Pre-train on entire pre-training set\n",
    "RandomForestRegressor: 0.4857\n",
    "AdaBoostRegressor: 0.5774\n",
    "XGBRegressor: 0.5084\n",
    "LinearRegression: 0.5542\n",
    "KNeighborsRegressor: 0.5064\n",
    "\n",
    "# Pre-train a model for each restaurant\n",
    "RandomForestRegressor: 0.5078\n",
    "XGBRegressor: 0.4972\n",
    "RidgeRegression: 0.4949\n",
    "KNeighborsRegressor: 0.5768\n",
    "Univariate forecasting with Prophet: 0.5420\n",
    "    \n",
    "# Conclusion from pre-training\n",
    "Most time-series forecasting techniques do not work well, \n",
    "because for each restaurant id, there are many missing days, \n",
    "e.g. Fridays/Saturdays jump to Sundays, and there are also\n",
    "some missing months such as May. Therefore, this problem\n",
    "is better to be solved using regression methods, which means\n",
    "that we can assume every data sample is independent.\n",
    "\n",
    "How to obtain the final result?\n",
    "From the pre-training outcomes, two schemes can be followed.\n",
    "1. Train a model for each restaurant, using\n",
    "RidgeRegression and RandomForestRegressoror.\n",
    "2. Train three models on the entire training set, using\n",
    "RandomForestRegressor, XGBRegressor and KNeighborsRegressor.\n",
    "\n",
    "Suppose procedure 1 gives result res1 and procedure 2 gives res2, \n",
    "res3, res4. The final result is then an ensemble or stacking of res1~res4.\n",
    "Now, let's move on with our plan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
