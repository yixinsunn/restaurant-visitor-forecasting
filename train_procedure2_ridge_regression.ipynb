{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/yixin/Desktop/Machine_Learning_Projects/restaurant-visitor-forecasting'\n",
    "np.random.seed(2018)\n",
    "\n",
    "data = {\n",
    "    'air_visit': pd.read_csv(path + '/input/air_visit_data.csv', parse_dates=['visit_date']), # main training set\n",
    "    'holidays': pd.read_csv(path + '/input/date_info.csv', parse_dates=['calendar_date']).rename(\n",
    "        columns={'calendar_date': 'visit_date'}),\n",
    "    'submission': pd.read_csv(path + '/input/sample_submission.csv')  # test set\n",
    "}\n",
    "\n",
    "data['holidays'].drop(['day_of_week'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "###                                        Data Preparation                                         ###\n",
    "#######################################################################################################\n",
    "# Add day of week, month into training set and test set\n",
    "data['submission']['visit_date'] = data['submission']['id'].apply(lambda x:x[-10:])\n",
    "data['submission']['visit_date'] = pd.to_datetime(data['submission']['visit_date'])\n",
    "data['submission']['air_store_id'] = data['submission']['id'].apply(lambda x:x[:-11])\n",
    "data['submission'].drop(['id'], axis=1, inplace=True)\n",
    "for df in ['air_visit', 'submission']:\n",
    "    data[df]['day_of_week'] = data[df]['visit_date'].dt.dayofweek\n",
    "    data[df]['month'] = data[df]['visit_date'].dt.month\n",
    "    data[df]['year'] = data[df]['visit_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate the min, max, median, and mean of visitors grouped by each store and day of week\n",
    "unique_stores = data['submission']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'day_of_week': [i] * len(unique_stores)}) \\\n",
    "                    for i in range(7)], ignore_index=True)\n",
    "\n",
    "funcs = {\n",
    "    'min': 'visitors_min',\n",
    "    'max': 'visitors_max',\n",
    "    'mean': 'visitors_mean',\n",
    "    'median': 'visitors_median'\n",
    "    ##'count': 'visitors_count'\n",
    "}\n",
    "for func in funcs:\n",
    "    tmp = data['air_visit'].groupby(['air_store_id', 'day_of_week'], as_index=False).agg(\n",
    "    {'visitors': func}).rename(columns={'visitors': funcs[func]})\n",
    "    stores = stores.merge(tmp, how='left', on=['air_store_id', 'day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge training and test sets with holidays\n",
    "train = pd.merge(data['air_visit'], data['holidays'], how='left', on='visit_date')\n",
    "test = pd.merge(data['submission'], data['holidays'], how='left', on='visit_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge training and test sets with store information\n",
    "train = pd.merge(train, stores, how='inner', on=['air_store_id', 'day_of_week'])\n",
    "test = pd.merge(test, stores, how='inner', on=['air_store_id', 'day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add interaction terms\n",
    "for df in [train, test]:\n",
    "    df['min_min'] = df['visitors_min'] * df['visitors_min']\n",
    "    df['mean_mean'] = df['visitors_mean'] * df['visitors_mean']\n",
    "    df['median_median'] = df['visitors_median'] * df['visitors_median']\n",
    "    df['min_max'] = df['visitors_min'] * df['visitors_max']\n",
    "    df['min_mean'] = df['visitors_min'] * df['visitors_mean']\n",
    "    df['min_median'] = df['visitors_min'] * df['visitors_median']\n",
    "    df['max_mean'] = df['visitors_max'] * df['visitors_mean']\n",
    "    df['max_median'] = df['visitors_max'] * df['visitors_median']\n",
    "    df['mean_median'] = df['visitors_mean'] * df['visitors_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperate data according to air_store_id.\n",
    "# X_train, X_test: <(float)air_store_id, (DataFrame)data for this id>\n",
    "# y_train: <(float)air_store_id, (DataFrame)labels>\n",
    "X_train, X_test, y_train = {}, {}, {}\n",
    "le = preprocessing.LabelEncoder()\n",
    "drop_columns = ['air_store_id', 'visit_date', 'visitors']\n",
    "categorical_columns = ['month', 'day_of_week']\n",
    "\n",
    "for store_id in train['air_store_id'].unique():\n",
    "    if store_id in X_train:\n",
    "        continue\n",
    "    tmp1 = train[train['air_store_id'] == store_id]\n",
    "    tmp1 = utils.shuffle(tmp1).reset_index(drop=True)\n",
    "    tmp2 = test[test['air_store_id'] == store_id]\n",
    "    y_train[store_id] = np.log1p(tmp1['visitors'])\n",
    "    \n",
    "    tmp = pd.concat([tmp1, tmp2], ignore_index=True)\n",
    "    tmp = pd.get_dummies(tmp, columns=categorical_columns)\n",
    "    tmp['year'] = le.fit_transform(tmp['year'])\n",
    "    tmp.drop(drop_columns, axis=1, inplace=True)\n",
    "    \n",
    "    X_train[store_id] = tmp[:tmp1.shape[0]]\n",
    "    X_test[store_id] = tmp[tmp1.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute missing data in X_test\n",
    "missing_columns = test.columns[test.isnull().any()]\n",
    "missing_ids = test['air_store_id'][test[missing_columns[0]].isnull()].unique()\n",
    "for store_id in missing_ids:\n",
    "    known = X_train[store_id].drop(missing_columns, axis=1)\n",
    "    unknown = X_test[store_id][X_test[store_id][missing_columns[0]].isnull()].drop(missing_columns, axis=1)\n",
    "    neigh = neighbors.NearestNeighbors(n_neighbors=10, algorithm='brute', n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(known)\n",
    "    for idx in unknown.index:\n",
    "        idx_nei = neigh.kneighbors(unknown.loc[idx].values.reshape(1, -1), return_distance=False)\n",
    "        X_test[store_id].loc[idx] = X_test[store_id].loc[idx].fillna(\n",
    "            X_train[store_id].iloc[idx_nei[0]][missing_columns].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the evaluation metric\n",
    "def RMSE(y_true, y_pred):\n",
    "    return metrics.mean_squared_error(y_true, y_pred) ** 0.5\n",
    "rmse = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "###                                             Training                                            ###\n",
    "###                   Train a ridge regression model for each store id individually                 ###\n",
    "#######################################################################################################\n",
    "alphas = np.logspace(-2, 9, base=2, num=500)\n",
    "ridge_cv = linear_model.RidgeCV(alphas=alphas, scoring=rmse, cv=3)\n",
    "\n",
    "model = {}; iteration = 0\n",
    "for store_id in train['air_store_id'].unique():\n",
    "    # select the optimal ridge regression model using cv\n",
    "    ridge_cv.fit(X_train[store_id], y_train[store_id])\n",
    "    model_ridge = linear_model.Ridge(alpha=ridge_cv.alpha_, max_iter=0x7fffffff)\n",
    "    model_ridge.fit(X_train[store_id], y_train[store_id])\n",
    "    model[store_id] = model_ridge\n",
    "    \n",
    "    ##cv_res = np.array(model_selection.cross_val_score(model_ridge, \n",
    "    ##                    X=X_train[store_id], y=y_train[store_id], scoring=rmse, n_jobs=-1, cv=3))\n",
    "    ##print(np.negative(cv_res) ** 0.5, np.negative(cv_res.mean()) ** 0.5)\n",
    "    print('Best l2 regularization term:', ridge_cv.alpha_)\n",
    "    print('Iteration {} is finished'.format(iteration))\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on entire training set: 0.481146080022\n"
     ]
    }
   ],
   "source": [
    "# Estimate model performance on entire training set\n",
    "y_true, y_pred = pd.DataFrame(), pd.DataFrame()\n",
    "for store_id in train['air_store_id'].unique():\n",
    "    y_true = pd.concat([y_true, y_train[store_id]])\n",
    "    yhat = model[store_id].predict(X_train[store_id])\n",
    "    y_pred = pd.concat([y_pred, pd.DataFrame(yhat)])\n",
    "print('RMSLE on entire training set:', RMSE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set and generate submission\n",
    "test['visitors'] = 0.0\n",
    "for store_id in train['air_store_id'].unique():\n",
    "    yhat = model[store_id].predict(X_test[store_id])\n",
    "    test['visitors'][test['air_store_id'] == store_id] = yhat\n",
    "\n",
    "test['visit_date'] = test['visit_date'].astype(str)\n",
    "test['id'] = test['air_store_id'] + '_' + test['visit_date']\n",
    "test_sub = test.drop([col for col in test.columns if col not in ['id', 'visitors']], axis=1)\n",
    "test_sub['visitors'] = np.expm1(test_sub['visitors']).clip(lower=0.)\n",
    "\n",
    "submission = pd.read_csv(path + '/input/sample_submission.csv').drop('visitors', axis=1)\n",
    "submission = submission.merge(test_sub, on='id', how='inner')\n",
    "submission.to_csv(path + '/output/train2_lin_20171223.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "\n",
    "filename = 'model_lin.data'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
